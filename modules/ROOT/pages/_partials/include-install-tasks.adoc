// tag::licenseKey[]
== Insert the Mule License Key

[IMPORTANT]
====
The procedures in the section must be performed by an IT administrator.
====

After the installation has completed succesfully, insert the Mule license key.

. Base64 encode the new Mule `.lic` license file provided by MuleSoft:
+
* On MacOS, run the following command:
+
[source,copy]
----
BASE64_ENCODED_LICENSE=$(base64 -b0 license.lic)
----
+
* On Unix, run the following command:
+
[source,copy]
----
BASE64_ENCODED_LICENSE=$(base64 -w0 license.lic)
----
+
* On Windows, choose one of the following:

** Use a WSL or Cygwin shell that includes the base64 tool and use the above Unix command.
** Use the base64.exe program included with Windows git (C:\Program Files\Git\usr\bin).
** Use the following Powershell command:
+
[source,copy]
----
$BASE64_ENCODED_LICENSE=[convert]::ToBase64String((Get-Content -path "license.lic" -Encoding byte))
----

. On the controller node acting as the leader during installation (the installer node), use the `rtfctl` utility with the Base64 value of your license key: 
+
[source,copy]
----
rtfctl apply mule-license $BASE64_ENCODED_LICENSE
----

. To verify the Mule license key has applied correctly, run:
+
[source,copy]
----
rtfctl get mule-license
----
// end::licenseKey[]

// tag::ingressResource[]

== Configure the Ingress Resource Template

[IMPORTANT]
====
The procedures in this section should be performed by an IT administrator.
====

If your ingress controller requires custom annotations and ingress class definition, follow the instructions in xref:custom-ingress-configuration.adoc[Defining a Custom Ingress Configuration].

[NOTE]
====
For GKE customers, the ingress controller included with GKE will provision a separate HTTP load balancer per application by default. Please read this link:https://help.mulesoft.com/s/article/Default-Ingress-Controller-Behavior-with-Runtime-Fabric-on-GKE[KB article] for more details.
====
// end::ingressResource[]

// tag::validate[]
== Validate Your Runtime Fabric

[IMPORTANT]
====
The procedures in this section should be performed by an IT administrator.
====

After completing the installation, your Runtime Fabric should be activated within your Anypoint organization. To validate your installation, go to Anypoint Runtime Manager and confirm that the status of the Runtime Fabric is `Active`.

Before deploying an application to your Runtime Fabric:

. Associate the Runtime Fabric with at least one Anypoint environment.
. Review and update the Inbound Traffic settings based upon your Kubernetes environment.
. Deploy an application to verify that Runtime Fabric is installed and configured correctly.
// end::validate[]

// tag::namespace[]

== Create A Namespace for Runtime Fabric 

You must create a namespace named `rtf` in your Kubernetes cluster. This namespace is where you install Runtime Fabric components. 

To create the namespace, run: 

[source,copy]
----
kubectl create ns rtf 
----
// end::namespace[]

// tag::pullsecret[]

== Create A Docker Pull Secret 

After you create the namespace, create a pull secret so you can retrieve the Docker images needed to install and run Runtime Fabric. 

The default registry URL is `rtf-runtime-registry.kprod.msap.io`. If youâ€™re using a local registry, specify those values here. 

To create the pull secret, run:

[source,copy]
----
kubectl create secret docker-registry <pull_secret> --namespace rtf --docker-server=<docker_registry_url> --docker-username=<docker_registry_username> --docker-password=<docker_ registry_password>
----
// end::pullsecret[]

// tag::sharedtenancy[]

== (Optional) Configure Shared Tenancy

If you want to configure xref:shared-tenancy.adoc[shared tenancy], add the required Kubernetes objects. The objects include:

* clusterRoles/Roles
* serviceAccounts
* clusterRoleBindings/roleBindings

. In your cluster, create a file call `configuration.yml`.
. Copy and paste the following:
+
[source,copy]
----
##rtf-agent ServiceAccount
apiVersion: v1
kind: ServiceAccount
metadata:
  namespace: ${RTF_NAMESPACE}
  name: rtf-agent
  labels:
    {{- include "labels.standard" . | nindent 4 }}
imagePullSecrets:
  - name: ${RTF_PULL_SECRET}

## rtf:agent ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: rtf:agent
  labels:
    {{- include "labels.standard" . | nindent 4 }}
rules:
  - apiGroups: ["extensions", "apps"]
    resources: ["deployments", "deployments/scale", "daemonsets", "replicasets"]
    verbs: ["get", "watch", "list", "create", "update", "patch", "delete"]
  - apiGroups: [""]
    resources: ["events", "pods", "pods/log", "pods/exec", "nodes"]
    verbs: ["get", "watch", "list"]
  - apiGroups: [""]
    resources: ["pods/portforward", "configmaps", "namespaces", "secrets", "services", "serviceaccounts", "events"]
    verbs: ["get", "watch", "list", "create", "update", "patch", "delete"]
  - apiGroups: ["batch", "extensions"]
    resources: ["jobs", "cronjobs"]
    verbs: ["get", "watch", "list", "create", "update", "patch", "delete", "deletecollection"]
  - apiGroups: ["policy"]
    resources: ["podsecuritypolicies"]
    resourceNames: ["rtf-restricted"]
    verbs: ["use"]
  - apiGroups: ["policy", "networking.k8s.io"]
    resources: ["podsecuritypolicies", "networkpolicies"]
    verbs: ["*"]
  - apiGroups: ["rbac.authorization.k8s.io"]
    resources: ["rolebindings", "roles"]
    verbs: ["get", "watch", "list", "create", "update", "patch", "delete"]
  - apiGroups: ["extensions", "networking.k8s.io"]
    resources: ["ingresses", "networkpolicies"]
    verbs: ["get", "watch", "list", "create", "update", "patch", "delete"]
  - apiGroups: ["policy"]
    resources: ["podsecuritypolicies"]
    verbs: ["use"]
  - apiGroups: ["rtf.mulesoft.com"]
    resources: ["persistencegateways"]
    verbs: ["get", "watch", "list", "create", "update", "patch", "delete"]
  - apiGroups: ["autoscaling"]
    resources: ["horizontalpodautoscalers"]
    verbs: ["*"]

## rtf-agent RoleBinding for rtf namespace
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: rtf:agent
  namespace: ${RTF_NAMESPACE}
  labels:
    {{- include "labels.standard" . | nindent 4 }}
subjects:
  - kind: ServiceAccount
    name: rtf-agent
    namespace: ${RTF_NAMESPACE}
roleRef:
  kind: ClusterRole
  name: rtf:agent
  apiGroup: rbac.authorization.k8s.io

## rtf-agent RoleBinding for App namespaces
### NOTE: Add RoleBindings for all the required namespaces for rtf:agent ClusterRole
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: rtf:agent
  namespace: ${APP_NAMESPACE}
  labels:
    {{- include "labels.standard" . | nindent 4 }}
subjects:
  - kind: ServiceAccount
    name: rtf-agent
    namespace: ${RTF_NAMESPACE}
roleRef:
  kind: ClusterRole
  name: rtf:agent
  apiGroup: rbac.authorization.k8s.io

## scc ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
name: ${RTF_NAMESPACE}
namespace: {{ .Release.Namespace }}
roleRef:
apiGroup: rbac.authorization.k8s.io
kind: ClusterRole
name: system:openshift:scc:anyuid
subjects:
- kind: ServiceAccount
  name: rtf-agent
  namespace: {{ .Release.Namespace }}
- kind: ServiceAccount
  name: mule-clusterip-service
  namespace: {{ .Release.Namespace }}
- kind: ServiceAccount
  name: resource-cache
  namespace: {{ .Release.Namespace }}
- kind: ServiceAccount
  name: rtf-persistence-gateway
  namespace: {{ .Release.Namespace }}
- kind: ServiceAccount
  name: cluster-status
  namespace: {{ .Release.Namespace }}
- kind: ServiceAccount
  name: am-log-forwarder
  namespace: {{ .Release.Namespace }}

## ClusterRole to read underlying Open Shift version
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: rtf-cluster-version-reader
rules:
  - apiGroups:
      - config.openshift.io
    resources:
      - clusterversions
    verbs:
      - get
      - list

## ClusterRoleBinding for the OpenShift version reader role
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: rtf-cluster-version-reader-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: rtf-cluster-version-reader
subjects:
  - kind: ServiceAccount
    name: rtf-agent
    namespace: ${RTF_NAMESPACE}

## ClusterRole for permissions to access nodes and pods
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: rtf:agent-extension
  labels:
    {{- include "labels.standard" . | nindent 4 }}
rules:
  apiGroups: [""]
  resources: ["nodes", "pods"]
  verbs: ["get", "list", "watch"]

## ClusterRoleBinding for the extension of rtf:agent role
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: rtf:agent-extension
  labels:
    {{- include "labels.standard" . | nindent 4 }}
subjects:
  - kind: ServiceAccount
    name: rtf-agent
    namespace:  ${RTF_NAMESPACE}
roleRef:
  kind: ClusterRole
  name: rtf:agent-extension
  apiGroup: rbac.authorization.k8s.io

## PSP for edge
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: sf-edge
  labels:
    {{- include "labels.standard" . | nindent 4 }}
spec:
  privileged: false
  hostNetwork: true
  seLinux:
    rule: RunAsAny
  supplementalGroups:
    rule: RunAsAny
  runAsUser:
    rule: RunAsAny
  fsGroup:
    rule: RunAsAny
  hostPorts:
  - min: 0
    max: 65535
  volumes:
  - '*'

## ServiceAccount for edge-user
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sf-edge
  namespace: ${RTF_NAMESPACE}
  labels:
    {{- include "labels.standard" . | nindent 4 }}
imagePullSecrets:
  - name: ${RTF_PULL_SECRET}

## ClusterRole for edge user
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: sf-edge-user
  labels:
    {{- include "labels.standard" . | nindent 4 }}
rules:
- apiGroups:
  - networking.k8s.io
  - extensions
  resources:
  - ingresses
  verbs:
  - watch
- apiGroups:
  - policy
  resourceNames:
  - sf-edge
  resources:
  - podsecuritypolicies
  verbs:
  - use
- apiGroups:
  - ""
  resources:
  - configmaps
  - secrets
  verbs:
  - list
  - get

## RoleBinding for edge to app namespaces
### NOTE: Add RoleBindings for all the required namespaces for sf-edge-user ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: edge-clusterrole-binding
  namespace: ${APP_NAMESPACE}
  labels:
    app.kubernetes.io/instance: rtf-automation
subjects:
- kind: ServiceAccount
  name: sf-edge
  namespace: ${RTF_NAMESPACE}
roleRef:
  kind: ClusterRole
  name: sf-edge-user
  apiGroup: rbac.authorization.k8s.io

## PodSecurityPolicy for Persistence Gateway
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: persistence-gateway-psp
  labels:
    {{- include "labels.standard" . | nindent 4 }}
spec:
  privileged: false
  seLinux:
    rule: RunAsAny
  supplementalGroups:
    rule: RunAsAny
  runAsUser:
    rule: RunAsAny
  fsGroup:
    rule: RunAsAny
  hostPorts:
    - min: 0
      max: 65535
  volumes:
    - '*'
----

// end::sharedtenancy[]